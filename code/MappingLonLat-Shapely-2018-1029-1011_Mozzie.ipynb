{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Longitude and Latitude to GeoJSON polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "https://stackoverflow.com/questions/20776205/point-in-polygon-with-geojson-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from shapely.geometry import shape, Point\n",
    "mappath = '/home/lmtdreamer/NYCTaxi/nyu-2451-36743-geojson.json'\n",
    "readpath = '/media/sf_Temp/Disk_E-NYC/5-3rd_cleaned/Green/cleaned_2013_Green.csv'\n",
    "writepath = '/media/sf_Temp/Disk_E-NYC/6-convertLonLat/2013_Green_map.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_zone(mappath,readpath,writepath,windows=True):\n",
    "    axis = ('PU_Lon','PU_Lat','DO_Lon','DO_Lat')\n",
    "    rf = open(readpath,'r') # 開啟檔案\n",
    "    head = rf.readline() # 讀取一行 (row) 之後換行\n",
    "    head = head.split(',') # 每行的欄位用 , 分隔\n",
    "    if windows:\n",
    "        head[-1] = head[-1][:-1] #去除末端的換行符號\n",
    "    wf = open(writepath, \"w\")\n",
    "    wf.write('row_id,PULocationID,DOLocationID\\n') # NOT withcolumn (cause not PySpark)?  Also, only 2 columns without other data from original CSV?\n",
    "    for i in range(len(head)):\n",
    "        if head[i] == axis[0]:\n",
    "            pu_lon_ = i\n",
    "        elif head[i] == axis[1]:\n",
    "            pu_lat_ = i\n",
    "        elif head[i] == axis[2]:\n",
    "            do_lon_ = i\n",
    "        elif head[i] == axis[3]:\n",
    "            do_lat_ = i\n",
    "    with open(mappath) as f:\n",
    "                        js = json.load(f)\n",
    "    try:\n",
    "        row_cnt=0\n",
    "        row_id = 0\n",
    "        while True:\n",
    "            line = rf.readline() # head = rf.readline()???\n",
    "            if line:\n",
    "                row_id += 1\n",
    "                row = line.split(',') # head = head.split(',')???\n",
    "                if windows:\n",
    "                    row[-1] = row[-1][:-1] # 去除末端的換行符號\n",
    "                if len(row)==len(head):\n",
    "                    new_row=''\n",
    "                    pu_lon = row[pu_lon_]\n",
    "                    pu_lat = row[pu_lat_]\n",
    "                    do_lon = row[do_lon_]\n",
    "                    do_lat = row[do_lat_]\n",
    "                    point1 = Point(float(pu_lon), float(pu_lat))\n",
    "                    point2 = Point(float(do_lon), float(do_lat))\n",
    "                    for feature in js['features']:\n",
    "                        polygon = shape(feature['geometry'])\n",
    "                        if polygon.contains(point1):\n",
    "                            zone1 = str(feature['properties']['locationid']) # zone1 or PULocationID???\n",
    "                        if polygon.contains(point2):\n",
    "                            zone2 = str(feature['properties']['locationid']) # zone2 or DOLocationID???\n",
    "                            new_row = str(row_id)+','+zone1+','+zone2 # PULocationID+','+DOLocationID???\n",
    "                    wf.write(new_row+'\\n')\n",
    "                    row_cnt+=1\n",
    "            else:\n",
    "                print('rows:',str(row_cnt))\n",
    "                break\n",
    "    finally:\n",
    "        rf.close()\n",
    "        wf.close()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PU_Time', 'DO_Time', 'Rate_Code', 'DO_Lat', 'Trip_Distance', 'Fare_Amt', 'Extra', 'Tip_Amt', 'PU_Lon', 'PU_Lat', 'DO_Lon\\n']\n",
      "12/06/2013 12:11:05 PM\n",
      "12/06/2013 12:14:06 PM\n",
      "1\n",
      "40.811981201171875\n",
      "0.5\n",
      "4\n",
      "0\n",
      "0\n",
      "-73.965065002441406\n",
      "40.806140899658203\n",
      "-73.962234497070312\n"
     ]
    }
   ],
   "source": [
    "# 檢查讀取到的檔案格式\n",
    "\n",
    "axis = ('PU_Lon','PU_Lat','DO_Lon','DO_Lat')\n",
    "rf = open(readpath,'r')\n",
    "head = rf.readline().split(',')\n",
    "print(head)\n",
    "line = rf.readline().split(',')\n",
    "line[-1] = line[-1][:-1]\n",
    "for i in line:\n",
    "    print(i)\n",
    "rf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166,166\n"
     ]
    }
   ],
   "source": [
    "# 測試單行讀取載客上車經緯度與下車經緯度\n",
    "\n",
    "rf = open(readpath,'r')\n",
    "head = rf.readline().split(',')\n",
    "line = rf.readline().split(',')\n",
    "line[-1] = line[-1][:-1]\n",
    "x,y=line[-1],line[3]\n",
    "x1,y1=line[-3],line[-2]\n",
    "point1 = Point(float(x), float(y))\n",
    "point2 = Point(float(x1), float(y1))\n",
    "with open(mappath) as f:\n",
    "    js = json.load(f)\n",
    "    for feature in js['features']:\n",
    "        polygon = shape(feature['geometry'])\n",
    "        if polygon.contains(point1):\n",
    "            zone1 = str(feature['properties']['locationid']) # zone1 or PULocationID???\n",
    "        if polygon.contains(point2):\n",
    "            zone2 = str(feature['properties']['locationid']) # zone2 or DOLocationID???\n",
    "    new_row = zone1+','+zone2 # PULocationID+','+DOLocationID???\n",
    "    print(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 1210811\n"
     ]
    }
   ],
   "source": [
    "cal_zone(mappath,readpath,writepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013_Green_map.csv  2013_Green_map-test-Local.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls /media/sf_Temp/Disk_E-NYC/6-convertLonLat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat /media/sf_Temp/Disk_E-NYC/6-convertLonLat/2013_Green_map.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11/30/2013 07:41:33 PM', '11/30/2013 08:00:43 PM', '1', '40.769596099853516', '4.91', '19', '0', '3.8', '-73.951805114746094', '40.810401916503906', '-73.98931884765625']\n",
      "['12/11/2013 02:25:03 PM', '12/11/2013 02:35:46 PM', '1', '40.682834625244141', '0.88', '8', '0', '0', '-73.982772827148438', '40.688484191894531', '-73.970779418945313']\n",
      "['12/15/2013 06:41:25 AM', '12/15/2013 06:45:51 AM', '1', '40.917964935302734', '1.04', '5.5', '0', '0', '-73.902175903320312', '40.931411743164063', '-73.901054382324219']\n",
      "['11/28/2013 06:28:03 PM', '11/28/2013 06:38:27 PM', '1', '40.801395416259766', '2.04', '9.5', '0', '1.5', '-73.93890380859375', '40.805084228515625', '-73.965950012207031']\n"
     ]
    }
   ],
   "source": [
    "p = '/media/sf_Temp/Disk_E-NYC/5-3rd_cleaned/Green/cleaned_2013_Green.csv'\n",
    "rf = open(p,'r') # 開啟檔案\n",
    "for i in range(117804):\n",
    "    head = rf.readline() # 讀取一行 (row) 之後換行\n",
    "head = head.split(',')\n",
    "head[-1] = head[-1][:-1]\n",
    "print(head)\n",
    "for i in range(3):\n",
    "    head = rf.readline()\n",
    "    head = head.split(',')\n",
    "    head[-1] = head[-1][:-1]\n",
    "    print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "point = Point(-73.93890380859375, 40.805084228515625)\n",
    "for feature in js['features']:\n",
    "    polygon = shape(feature['geometry'])\n",
    "    if polygon.contains(point):\n",
    "        zone = feature['properties']['locationid']\n",
    "        print(zone)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappath = 'nyu-2451-36743-geojson.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original code to map (Longitude,Latitude) set to NYC Taxi Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load GeoJSON file containing sectors\n",
    "with open('nyu-2451-36743-geojson.json') as f:\n",
    "    js = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(js['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 讀取全部 263 區域\n",
    "# js['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js['features'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct point based on lon/lat returned by geocoder\n",
    "# 隨便給一個點的經緯度\n",
    "point = Point(-73.9919569999999, 40.721567)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check each polygon to see if it contains the point\n",
    "# 看看剛剛給的點是不是在某一個區域中\n",
    "\n",
    "for feature in js['features']:\n",
    "    polygon = shape(feature['geometry'])\n",
    "    if polygon.contains(point):\n",
    "        zone = feature['properties']['locationid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
